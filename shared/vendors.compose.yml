include:
  - .docker/supabase/docker-compose.yml
  - vendors/local-ai-packaged/docker-compose.yml

services:
  mcp-bravesearch:
    image: mcp/brave-search
    environment:
      - BRAVE_API_KEY=${BRAVE_API_KEY}
    container_name: mcp-bravesearch
    tty: true
  mcp-crawl4ai-rag:
    build:
      context: vendors/mcp-crawl4ai-rag
      dockerfile: Dockerfile
    container_name: mcp-crawl4ai-rag
    ports:
      - 8003:8051
    expose:
      - 8051
    environment:
      USE_AGENTIC_RAG: False
      USE_HYBRID_SEARCH: True
      USE_RERANKING: True
      SUPABASE_URL: ${SUPABASE_PROJECT_URL}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      TRANSPORT: sse
      USE_KNOWLEDGE_GRAPH: true
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      HOST: 0.0.0.0
      PORT: 8051
    networks:
      - internal
  mcp-qdrant:
    build:
      context: vendors/mcp-qdrant
      dockerfile: Dockerfile
    container_name: mcp-qdrant
    ports:
      - 8004:8000
    expose:
      - 8000
    environment:
      QDRANT_URL: ${QDRANT_URL:-http://qdrant:6333}
      QDRANT_API_KEY: ${QDRANT_API_KEY}
      COLLECTION_NAME: ${WORKSPACE_COLLECTION_NAME}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL}
      EMBEDDING_PROVIDER: ${EMBEDDING_PROVIDER}
      QDRANT_VERIFY_SSL: False
    depends_on:
      - qdrant
    networks:
      - internal
  mcp-filesystem:
    build:
      context: vendors/mcp-servers
      dockerfile: src/filesystem/Dockerfile
      target: release
  mcp-sequentialthinking:
    build:
      context: vendors/mcp-servers
      dockerfile: src/sequentialthinking/Dockerfile
      target: release
  mcp-memory:
    build:
      context: vendors/mcp-servers
      dockerfile: src/memory/Dockerfile
      target: release
  archon:
    build:
      context: vendors/Archon
      dockerfile: Dockerfile
    environment:
      - BASE_URL=http://ollama:11434
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
    expose:
      - 8100
      - 8501
    ports:
      - 8501:8501
  graphiti:
    build:
      context: vendors/graphiti
    ports:
      - "8888:8000"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/healthcheck')",
        ]
      interval: 10s
      timeout: 5s
      retries: 3
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - PORT=8000
  graphiti-mcp:
    build:
      context: vendors/graphiti/mcp_server
      dockerfile: Dockerfile
    env_file:
      - path: .env
        required: false # Makes the file optional. Default value is 'true'
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MODEL_NAME=${MODEL_NAME:-gpt-4o-mini}
      - PATH=/root/.local/bin:${PATH}
    ports:
      - "8005:8000" # Expose the MCP server via HTTP for SSE transport
    command: ["uv", "run", "graphiti_mcp_server.py", "--transport", "sse"]
