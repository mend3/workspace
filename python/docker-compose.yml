services:
  ai-context:
    platform: linux/amd64
    container_name: ai-context
    working_dir: /app
    build:
      context: .
      dockerfile: ./.docker/python3/Dockerfile
      args:
        - VECTOR_TOOL=vector_generator
    command: python -m python.generators.vector_from_files --root . --store qdrant --collection workspace_embedding --ignore-dirs "deployment,tmp,__pycache__,node_modules" --ignore-files "package-lock.json,yarn.lock,pnpm-lock.yaml"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONUNBUFFERED=1
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER}
      - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    volumes:
      - .:/app
    labels:
      logging: 'enabled'
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    depends_on:
      qdrant:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
