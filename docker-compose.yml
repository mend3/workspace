name: ${NAMESPACE:-workspace}

x-qdrant: &service-qdrant
  image: qdrant/qdrant
  container_name: qdrant
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
    - QDRANT__GPU__INDEXING=true
  volumes:
    - qdrant_data:/qdrant/storage
  ports:
    - '6333:6333'
  expose:
    - 6333
  restart: unless-stopped
  networks:
    - internal
  healthcheck:
    test: ['CMD', 'curl', '-f', 'http://localhost:6333/readyz']
    interval: 10s
    timeout: 5s
    retries: 5
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]

x-n8n: &service-n8n
  image: n8nio/n8n:latest
  networks: ['internal']
  environment:
    - DB_TYPE=postgres
    - DB_POSTGRESDB_HOST=postgres
    - DB_POSTGRESDB_USER=${POSTGRES_USER}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
    - N8N_DIAGNOSTICS_ENABLED=false
    - N8N_PERSONALIZATION_ENABLED=false
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    - N8N_USER_MANAGEMENT_DISABLED=false
    - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
    - N8N_DEFAULT_USER_EMAIL=${N8N_DEFAULT_USER_EMAIL}
    - N8N_DEFAULT_USER_PASSWORD=${N8N_DEFAULT_USER_PASSWORD}
    - N8N_BASIC_AUTH_ACTIVE=false
    - N8N_HOST=n8n.devshell.localhost
    - N8N_PORT=5678
    - WEBHOOK_URL=https://n8n.devshell.localhost
  depends_on:
    postgres:
      condition: service_healthy

x-ollama: &service-ollama
  image: ollama/ollama:latest
  container_name: ollama
  networks: ['internal']
  restart: unless-stopped
  ports:
    - 11434:11434
  environment:
    - VECTOR_STORE_PATH=/app/vector_store
    - NVIDIA_VISIBLE_DEVICES=all
  volumes:
    - ollama_data:/root/.ollama
    - ./.tmp/.ollama:/root/.ollama
    - ./.docker/ollama:/code
  healthcheck:
    test: ['CMD', 'curl', '-f', 'http://localhost:11434']
    interval: 10s
    timeout: 5s
    retries: 5

x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  container_name: ollama-pull-llama
  networks:
    - internal
  volumes:
    - ollama_data:/root/.ollama
  entrypoint: /bin/sh
  command:
    - '-c'
    - >
      set -e;
      sleep 3;
      OLLAMA_HOST=ollama:11434 ollama pull qwen2.5:7b &&
      OLLAMA_HOST=ollama:11434 ollama pull all-minilm:l6-v2 &&
      OLLAMA_HOST=ollama:11434 ollama pull nomic-embed-text

services:
  traefik:
    image: traefik
    container_name: traefik
    command:
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --api.dashboard=true
      - --certificatesresolvers.selfsigned.acme.tlschallenge=false
      - --log.level=INFO
      - --accesslog=true
      - '--providers.file.filename=/etc/traefik/tls.yml'
    ports:
      - '80:80'
      - '443:443'
    networks:
      - internal
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - .docker/traefik/config.yaml:/etc/traefik/traefik.yaml:ro
      - .docker/traefik/certs:/certs:ro
    labels:
      traefik.enable: "true"
      traefik.http.routers.traefik.rule: Host(`workspace.com`)
      traefik.http.routers.traefik.service: api@internal
      traefik.http.routers.traefik.tls: true
      traefik.http.routers.traefik.entrypoints: websecure
      traefik.http.services.traefik.loadbalancer.server.port: 8080
  n8n-import:
    <<: *service-n8n
    container_name: n8n-import
    entrypoint: /bin/sh
    command:
      - '-c'
      - >
        n8n import:credentials --separate --input=/backup/credentials &&
        n8n import:workflow --separate --input=/backup/workflows
    volumes:
      - ./.docker/n8n/backup:/backup:ro

  n8n:
    <<: *service-n8n
    container_name: n8n
    restart: unless-stopped
    ports:
      - 5678:5678
    volumes:
      - n8n_data:/home/node/.n8n
      - ./.docker/n8n/backup:/backup
      - ./.docker/n8n/shared:/data/shared
    depends_on:
      n8n-import:
        condition: service_completed_successfully
    networks:
      - internal

  ollama:
    <<: *service-ollama
    profiles: ['cpu', 'gpu']
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-pull:
    <<: *init-ollama
    profiles: ['gpu']
    depends_on:
      ollama:
        condition: service_started
  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    container_name: open-webui
    runtime: nvidia
    ports:
      - '3000:8080'
    environment:
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - NVIDIA_VISIBLE_DEVICES=all
    depends_on:
      ollama-pull:
        condition: service_completed_successfully
    volumes:
      - openwebui_data:/app/backend/data
    networks:
      - internal
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    deploy:
      restart_policy:
        condition: always
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  postgres:
    image: postgres
    restart: always
    user: postgres
    environment:
      TZ: America/Sao_Paulo
      PGUSER: ${POSTGRES_USER}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: workspace
    healthcheck:
      test: pg_isready -U ${POSTGRES_USER} -d workspace
      interval: 2s
      timeout: 5s
      retries: 10
    networks:
      - internal
    expose:
      - 5432
    ports:
      - 5432:5432
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - .docker/postgres/sws/:/docker-entrypoint-initdb.d/:ro
  redis:
    platform: linux/amd64
    image: redislabs/rejson:2.0.6
    command: redis-server --loadmodule /usr/lib/redis/modules/rejson.so --loadmodule /usr/lib/redis/modules/redisearch.so --appendonly yes --maxclients 10000 --timeout 0 --tcp-keepalive 300 --save
    environment:
      - TZ=America/Sao_Paulo
      - REDISTIMESERIES_ARGS="RETENTION_POLICY=20"
    healthcheck:
      test:
        - CMD
        - redis-cli
        - ping
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    volumes:
      - redis_data:/data
    ports:
      - 6379:6379
    networks:
      - internal
    extra_hosts:
      - host.docker.internal:host-gateway
  mysql:
    restart: always
    image: mysql/mysql-server:${MYSQL_VERSION}
    command: ['--default-authentication-plugin', 'mysql_native_password']
    pid: host
    ports:
      - 3306:3306
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
    volumes:
      - ./.docker/mysql/mysqld.cnf:/etc/mysql/conf.d/mysqld.cnf
      - ./.docker/mysql/data:/var/lib/mysql
      - ./.docker/mysql/init:/docker-entrypoint-initdb.d/
    networks:
      - internal
  mongo:
    platform: linux/amd64
    image: mongo:4
    restart: always
    ports:
      - '27017:27017'
    environment:
      - MONGO_INITDB_DATABASE=${MONGODB_DATABASE}
      - MONGO_INITDB_ROOT_USERNAME=${MONGODB_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGODB_PASSWORD}
    healthcheck:
      test: echo $(mongo --eval 'db.runCommand("ping").ok')
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    networks:
      - internal
  pgvector:
    image: pgvector/pgvector:pg17
    container_name: pgvector-db
    environment:
      TZ: America/Sao_Paulo
      PGUSER: ${POSTGRES_USER}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: vector_db
    expose:
      - 5432
    networks:
      - internal
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready']
      interval: 1s
      timeout: 5s
      retries: 10
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - ./.docker/postgres/pgvector/:/docker-entrypoint-initdb.d/:ro
  pinecone:
    image: ghcr.io/pinecone-io/pinecone-local:latest
    container_name: pinecone
    expose:
      - 5081
    environment:
      - PORT=5081
      - PINECONE_HOST=${PINECONE_HOST:-localhost}
      - PINECONE_API_KEY=${PINECONE_API_KEY:-apilocal}
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT:-us-east1-gcp}
    networks:
      - internal
    volumes:
      - pinecone_data:/root/.pinecone
  qdrant:
    image: qdrant/qdrant:gpu-nvidia-latest
    environment:
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-fastembed}
      - QDRANT__GPU__INDEXING=true
    profiles: ['gpu']
    <<: *service-qdrant

networks:
  internal:
    driver: bridge

volumes:
  n8n_data:
  ollama_data:
  openwebui_data:
  postgres_data:
  redis_data:
  pgvector_data:
  pinecone_data:
  qdrant_data:
